# ğŸš€ ìë™ ì„¤ì • ê°€ì´ë“œ (Automated Setup Guide)

ì´ ë¬¸ì„œëŠ” FSFM-CVPR25 í”„ë¡œì íŠ¸ë¥¼ ë‹¤ë¥¸ í™˜ê²½ì—ì„œ í´ë¡ ë°›ì•˜ì„ ë•Œ ìë™ìœ¼ë¡œ í•„ìš”í•œ íŒŒì¼ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“¦ ìë™ìœ¼ë¡œ ì„¤ì¹˜ë˜ëŠ” í•­ëª©

Docker ì»¨í…Œì´ë„ˆë¥¼ ì‹œì‘í•˜ë©´ ë‹¤ìŒ í•­ëª©ë“¤ì´ ìë™ìœ¼ë¡œ í™•ì¸ ë° ì„¤ì¹˜ë©ë‹ˆë‹¤:

1. âœ… **FACER íˆ´í‚·** - Face parsingì„ ìœ„í•œ ë„êµ¬
2. âœ… **ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜** - ViT-S/B/L ëª¨ë¸
3. âš ï¸ **ë°ì´í„°ì…‹** - ì˜µì…˜ìœ¼ë¡œ ìë™ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥ (ëŒ€ìš©ëŸ‰)

---

## ğŸ³ Dockerë¡œ ìë™ ì„¤ì •í•˜ê¸° (ê¶Œì¥)

### 1ï¸âƒ£ ê¸°ë³¸ ì‚¬ìš© (ViT-B ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ)

```bash
# ë ˆí¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/your-repo/FSFM-CVPR25.git
cd FSFM-CVPR25

# Docker ì»¨í…Œì´ë„ˆ ë¹Œë“œ ë° ì‹œì‘
docker-compose up -d

# ì»¨í…Œì´ë„ˆ ì ‘ì†
docker exec -it fsfm-training bash
```

ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ:
- FACER íˆ´í‚·ì´ í´ë¡ ë©ë‹ˆë‹¤
- FS-VFM ViT-B ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤
- í•„ìš”í•œ ë””ë ‰í† ë¦¬ê°€ ìƒì„±ë©ë‹ˆë‹¤

### 2ï¸âƒ£ ë‹¤ë¥¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

`docker-compose.yml` íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ìˆ˜ì •:

```yaml
environment:
  - DOWNLOAD_MODEL=vit-l  # ViT-Large ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```

**ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:**
- `vit-s` - FS-VFM ViT-Small (ê°€ì¥ ë¹ ë¦„, ì„±ëŠ¥ ë‚®ìŒ)
- `vit-b` - FS-VFM ViT-Base (ê¸°ë³¸ê°’, ê· í˜•ì¡íŒ ì„±ëŠ¥)
- `vit-l` - FS-VFM ViT-Large (ê°€ì¥ ëŠë¦¼, ì„±ëŠ¥ ë†’ìŒ)
- `fsfm-vit-b` - FSFM ViT-Base (CVPR25 ë²„ì „)
- `all` - ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 10GB+)

### 3ï¸âƒ£ ë°ì´í„°ì…‹ ìë™ ë‹¤ìš´ë¡œë“œ (ì„ íƒì‚¬í•­)

âš ï¸ **ì£¼ì˜**: ë°ì´í„°ì…‹ì€ ë§¤ìš° í° ìš©ëŸ‰(ìˆ˜ì‹­~ìˆ˜ë°± GB)ì…ë‹ˆë‹¤!

```yaml
environment:
  - AUTO_DOWNLOAD_DATASET=true  # ì£¼ì„ í•´ì œ
```

---

## ğŸ’» Docker ì—†ì´ ìˆ˜ë™ ì„¤ì •

### 1ï¸âƒ£ Python í™˜ê²½ ì„¤ì •

```bash
# Conda í™˜ê²½ ìƒì„±
conda create -n fsfm3c python=3.9.21
conda activate fsfm3c

# PyTorch ì„¤ì¹˜
pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2ï¸âƒ£ FACER íˆ´í‚· ì„¤ì¹˜

```bash
cd datasets/pretrain/preprocess/tools
git clone https://github.com/FacePerceiver/facer.git
cd ../../../../
```

### 3ï¸âƒ£ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

**ë°©ë²• A: ìë™ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```bash
python3 setup_download_models.py --model vit-b
```

**ë°©ë²• B: ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```bash
cd fsvfm/pretrain
python download_pretrained_weitghts.py
```

**ë°©ë²• C: ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ**
- ğŸ¤— [Hugging Face Model Hub](https://huggingface.co/Wolowolo/fsfm-3c/tree/main/pretrained_models)ì—ì„œ ë‹¤ìš´ë¡œë“œ
- `fsvfm/pretrain/checkpoint/pretrained_models/` í´ë”ì— ì €ì¥

### 4ï¸âƒ£ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

**í…ŒìŠ¤íŠ¸ë§Œ í•˜ëŠ” ê²½ìš°:**
```bash
# Hugging Faceì—ì„œ ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
# ğŸ¤— https://huggingface.co/datasets/Wolowolo/DF_DiFF_FAS_dataset_in_FSFM_FSVFM/tree/main/finetune_datasets

# datasets/finetune_datasets/ í´ë”ì— ì••ì¶• í•´ì œ
```

**ì „ì²´ í•™ìŠµì„ í•˜ëŠ” ê²½ìš°:**
- VGGFace2, FaceForensics++, DiFF ë“±ì˜ ì›ë³¸ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
- README.mdì˜ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì„¹ì…˜ ì°¸ê³ 

---

## ğŸ” ì„¤ì • í™•ì¸

### ëª¨ë“  ê²ƒì´ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸:

```bash
# FACER íˆ´í‚· í™•ì¸
ls -la datasets/pretrain/preprocess/tools/facer

# ëª¨ë¸ ê°€ì¤‘ì¹˜ í™•ì¸
ls -la fsvfm/pretrain/checkpoint/pretrained_models/

# Python í™˜ê²½ í™•ì¸
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
```

---

## ğŸ¯ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

ì„¤ì •ì´ ì™„ë£Œë˜ë©´ ë°”ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥:

```bash
# Deepfake Detection í…ŒìŠ¤íŠ¸
cd fsvfm/finetune/cross_dataset_DFD_and_DiFF
bash scripts_DFD/run_DfD-ViT-B.sh
```

---

## ğŸ“ í•„ìš”í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡°

ìë™ ì„¤ì • í›„ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ê°€ ìƒì„±ë©ë‹ˆë‹¤:

```
FSFM-CVPR25/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ pretrain/
â”‚   â”‚   â””â”€â”€ preprocess/
â”‚   â”‚       â””â”€â”€ tools/
â”‚   â”‚           â””â”€â”€ facer/          # âœ… ìë™ í´ë¡ 
â”‚   â””â”€â”€ finetune_datasets/          # âš ï¸ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í•„ìš”
â”œâ”€â”€ fsvfm/
â”‚   â””â”€â”€ pretrain/
â”‚       â””â”€â”€ checkpoint/
â”‚           â””â”€â”€ pretrained_models/  # âœ… ìë™ ë‹¤ìš´ë¡œë“œ
â”œâ”€â”€ data/                           # âš ï¸ ì›ë³¸ ë°ì´í„° (ë§¤ìš° í¼)
â”œâ”€â”€ outputs/                        # í•™ìŠµ ê²°ê³¼
â”œâ”€â”€ logs/                           # ë¡œê·¸ íŒŒì¼
â””â”€â”€ checkpoints/                    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
```

---

## â“ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
# huggingface_hub ì¬ì„¤ì¹˜
pip install --upgrade huggingface_hub

# ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python3 setup_download_models.py --model vit-b
```

### ë¬¸ì œ 2: FACER íˆ´í‚· ì—ëŸ¬
```bash
# FACER ì¬ì„¤ì¹˜
cd datasets/pretrain/preprocess/tools
rm -rf facer
git clone https://github.com/FacePerceiver/facer.git
```

### ë¬¸ì œ 3: CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# docker-compose.ymlì—ì„œ GPU ì„¤ì • ì¡°ì •
environment:
  - CUDA_VISIBLE_DEVICES=0  # ì‚¬ìš©í•  GPU ë²ˆí˜¸ ì§€ì •
```

### ë¬¸ì œ 4: ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
```bash
# Docker ì´ë¯¸ì§€ ë° ì»¨í…Œì´ë„ˆ ì •ë¦¬
docker system prune -a --volumes

# í•„ìš”ì—†ëŠ” ëª¨ë¸ ì‚­ì œ (ì˜ˆ: all ë‹¤ìš´ë¡œë“œ í›„ ì¼ë¶€ë§Œ ì‚¬ìš©)
rm -rf fsvfm/pretrain/checkpoint/pretrained_models/FS-VFM_ViT-L_VF2_600e
```

---

## ğŸ”— ì¶”ê°€ ìë£Œ

- ğŸ“– [ë©”ì¸ README](./README.md) - ì „ì²´ í”„ë¡œì íŠ¸ ë¬¸ì„œ
- ğŸ¤— [Hugging Face Models](https://huggingface.co/Wolowolo/fsfm-3c)
- ğŸ¤— [Hugging Face Datasets](https://huggingface.co/datasets/Wolowolo/DF_DiFF_FAS_dataset_in_FSFM_FSVFM)
- ğŸ“ [Paper (arXiv)](https://arxiv.org/abs/2510.10663)

---

## ğŸ’¡ íŒ

1. **ë””ìŠ¤í¬ ê³µê°„ í™•ë³´**: ì „ì²´ ì„¤ì •ì—ëŠ” ì•½ 100GB+ í•„ìš”
2. **ë„¤íŠ¸ì›Œí¬**: ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì•ˆì •ì ì¸ ì¸í„°ë„· ì—°ê²° í•„ìš”
3. **GPU ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB VRAM ê¶Œì¥ (ViT-Lì€ 16GB+)
4. **ì²˜ìŒ ì‚¬ìš©**: ViT-B ëª¨ë¸ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥

---

**ë¬¸ì œê°€ í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´ [Issue](https://github.com/wolo-wolo/FSFM-CVPR25/issues)ë¥¼ ì—´ì–´ì£¼ì„¸ìš”!** ğŸ™

